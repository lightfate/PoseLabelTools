{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob,os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from myutil import *\n",
    "\n",
    "from mydataloader import FrameProcessor, YoloLoader, PoseModelLoader\n",
    "\n",
    "class myVideoLoader(object):\n",
    "    def __init__(self, videoPath):\n",
    "        self.videoPath = videoPath\n",
    "        self.dirPath , self.videoname = os.path.split(videoPath)\n",
    "        self.cap = cv2.VideoCapture(videoPath)\n",
    "        self.fps = int(self.cap.get(cv2.CAP_PROP_FPS)) \n",
    "        self.fcount = int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        \n",
    "    def get_audio(self):\n",
    "        cap = cv2.VideoCapture(self.videoPath)\n",
    "        ret, frame = cap.read()\n",
    "        self.audioPath = self.videoPath[:-4]+'.wav'\n",
    "        command = \"ffmpeg -i {} -vn -ar 16000 -f wav {}\".format(self.videoPath, self.audioPath)\n",
    "        try:\n",
    "            subprocess.check_call(command, shell=True)\n",
    "            is_success = True\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(\"error code: {}! shell command: {}\".format(e.returncode, e.cmd))\n",
    "            is_success = False\n",
    "        assert is_success==True, print('convert error!')\n",
    "        cap.release()\n",
    "        return self.audioPath\n",
    "     \n",
    "    \n",
    "    def extract_frame(self, savDir, by_sec=1, useFilter = True, min_det_num = 40, filter_jump_sec=5):\n",
    "        #by_sec=5 : save frame every 5 second \n",
    "        #useFilter, min_det_num : use alphapose to detect person number and filter the frame (detect_num<min_det_num)\n",
    "        #filter_jump_sec : if detect frame, jump x sec.\n",
    "        if not os.path.exists(savDir):\n",
    "            os.makedirs(savDir)\n",
    "            \n",
    "        if useFilter:\n",
    "            # Load model\n",
    "            pose_model_loader = PoseModelLoader()\n",
    "            det_model_loader = YoloLoader()\n",
    "            \n",
    "        cap = cv2.VideoCapture(self.videoPath)\n",
    "        fI_jump=0\n",
    "        for fI in tqdm(range(0,self.fcount,self.fps*by_sec)):\n",
    "            if fI<fI_jump:\n",
    "                continue\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES,fI)\n",
    "            ret, frame = cap.read()\n",
    "            if useFilter:\n",
    "                framePose = FrameProcessor(frame, det_model_loader, pose_model_loader).start()\n",
    "                result = framePose.resultNew\n",
    "                person_num = framePose.det_human_num\n",
    "                if person_num<min_det_num:\n",
    "                    continue\n",
    "            imgSavname=self.videoname[:-4]+'_'+str(fI)+'_'+str(person_num)+'.jpg'\n",
    "            jsonSavname=self.videoname[:-4]+'_'+str(fI)+'_'+str(person_num)+'.json'\n",
    "            sav_img(os.path.join(savDir,self.videoname[:-4],imgSavname), frame)\n",
    "            with open(os.path.join(savDir,self.videoname[:-4],jsonSavname),'w',encoding='utf-8') as jsonfile:\n",
    "                json.dump(result, jsonfile)\n",
    "            fI_jump = fI + self.fps*filter_jump_sec\n",
    "            #print(person_num, savname)\n",
    "        cap.release() \n",
    "    \n",
    "    def auto_extract_frame(self, savDir, by_sec=1, filter_jump_sec=5):\n",
    "        imgSavDir = os.path.join(savDir,self.videoname[:-4],'images')\n",
    "        jsonSavDir = os.path.join(savDir,self.videoname[:-4],'keypoints')\n",
    "        \n",
    "        if not os.path.exists(savDir):\n",
    "            os.makedirs(savDir)\n",
    "        if not os.path.exists(imgSavDir):\n",
    "            os.makedirs(imgSavDir)\n",
    "        if not os.path.exists(jsonSavDir):\n",
    "            os.makedirs(jsonSavDir)\n",
    "        \n",
    "        # Load model\n",
    "        pose_model_loader = PoseModelLoader()\n",
    "        det_model_loader = YoloLoader()\n",
    "            \n",
    "        cap = cv2.VideoCapture(self.videoPath)\n",
    "        fI_jump=0\n",
    "        fIList=[]\n",
    "        personNumList=[]\n",
    "        resultList=[]\n",
    "        for fI in tqdm(range(0,self.fcount,self.fps*by_sec)):\n",
    "            #if fI<fI_jump:\n",
    "                #continue\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES,fI)\n",
    "            ret, frame = cap.read()\n",
    "            framePose = FrameProcessor(frame, det_model_loader, pose_model_loader).start()\n",
    "            result = framePose.resultNew\n",
    "            personNum = framePose.det_human_num\n",
    "            personNumList.append(personNum)\n",
    "            resultList.append(result)\n",
    "            fIList.append(fI)\n",
    "            #fI_jump = fI + self.fps*filter_jump_sec\n",
    "        \n",
    "        personNumThre=int(0.9*max(personNumList))\n",
    "        for fI, personNum, result in tqdm(zip(fIList, personNumList, resultList)):\n",
    "            if personNum<personNumThre:\n",
    "                continue\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES,fI)\n",
    "            ret, frame = cap.read()\n",
    "            imgSavName=self.videoname[:-4]+'_'+str(fI)+'_'+str(personNum)+'.jpg'\n",
    "            jsonSavName=self.videoname[:-4]+'_'+str(fI)+'_'+str(personNum)+'_keypoints.json'\n",
    "            sav_img(os.path.join(imgSavDir, imgSavName), frame)\n",
    "            with open(os.path.join(jsonSavDir, jsonSavName),'w',encoding='utf-8') as jsonfile:\n",
    "                json.dump(result, jsonfile)\n",
    "        cap.release() \n",
    "\n",
    "videoDir=r'/home/ubuntu/Data/Video/class/'\n",
    "savDir='/home/ubuntu/Data/autoFrameFilter/'\n",
    "videoPathList = glob.glob(videoDir+'*.mp4')\n",
    "for videoPath in videoPathList:\n",
    "    testVideo = myVideoLoader(videoPath)\n",
    "    testVideo.auto_extract_frame(savDir,by_sec=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
